# SVM Gradient Descent (Hinge Loss Functions)

This implementation of the Support Vector Machines(SVM) algorithm is based on the concept of gradient descent. The loss function used here is the hinge loss function. You can learn more about it in this Medium post. Just click [here](https://towardsdatascience.com/solving-svm-stochastic-gradient-descent-and-hinge-loss-8e8b4dd91f5b)

In this repo you will find code that will enable you to create animated SVM convergence graphs. You can play with the learning rate and the regularization parameter lambda. 

<p align="center">
  <img width="50%" height="50%" src="animationSVM.gif">
</p>


